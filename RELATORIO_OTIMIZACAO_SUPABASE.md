# üìä RELAT√ìRIO DE OTIMIZA√á√ÉO DO BANCO SUPABASE

**Data:** 04 de Fevereiro de 2026
**Projeto:** Ap proposta - Sistema DRE RAIZ
**Limite Atual:** 500 MB (quase no limite)
**Objetivo:** Identificar e remover dados desnecess√°rios para otimizar o banco

---

## üéØ RESUMO EXECUTIVO

Seu banco Supabase est√° utilizando 5 tabelas principais, mas provavelmente a tabela `dre_fabric` √© a principal causadora do alto consumo de espa√ßo, pois ela:
- **N√ÉO √© usada pelo frontend da aplica√ß√£o**
- Serve apenas como espelho tempor√°rio dos dados do Microsoft Fabric
- Cont√©m dados brutos n√£o processados que j√° foram migrados para `transactions`

### üí∞ Economia Estimada de Espa√ßo

| Item | A√ß√£o | Economia Estimada |
|------|------|-------------------|
| Arquivos de log/erro no projeto | Deletar | ~156 MB (no projeto, n√£o no banco) |
| Tabela `dre_fabric` | Avaliar/Limpar | **50-80% do banco** |
| Registros antigos em `transactions` | Arquivar | 20-40% do banco |
| √çndices n√£o utilizados | Remover | 5-10% do banco |
| Tabelas de cruzamento/hist√≥rico | Limpar | 10-20% do banco |

---

## üìã AN√ÅLISE DAS TABELAS

### 1. **TABELAS USADAS ATIVAMENTE PELO FRONTEND** ‚úÖ

#### 1.1 `transactions`
- **Uso:** CR√çTICO - Principal tabela da aplica√ß√£o
- **Campos:** 25 colunas (id, date, description, amount, type, etc.)
- **√çndices:** 9 √≠ndices criados
- **A√ß√£o:** ‚ö†Ô∏è **OTIMIZAR - Manter apenas dados necess√°rios**

**Recomenda√ß√µes:**
```sql
-- 1. Verificar quantidade de registros e per√≠odo
SELECT
    COUNT(*) as total_registros,
    MIN(date) as data_mais_antiga,
    MAX(date) as data_mais_recente,
    pg_size_pretty(pg_total_relation_size('transactions')) as tamanho_total
FROM transactions;

-- 2. Analisar distribui√ß√£o por data
SELECT
    DATE_TRUNC('month', date::date) as mes,
    COUNT(*) as quantidade,
    pg_size_pretty(SUM(pg_column_size(transactions.*))) as tamanho_estimado
FROM transactions
GROUP BY mes
ORDER BY mes DESC;

-- 3. Identificar registros antigos (mais de 2 anos)
SELECT COUNT(*) as registros_antigos
FROM transactions
WHERE date < (CURRENT_DATE - INTERVAL '24 months');
```

**A√ß√µes sugeridas:**
- [ ] Mover registros com mais de 2 anos para tabela de arquivo hist√≥rico
- [ ] Considerar compacta√ß√£o de dados antigos
- [ ] Implementar pol√≠tica de reten√ß√£o de dados

---

#### 1.2 `manual_changes`
- **Uso:** Sistema de aprova√ß√µes
- **Impacto:** Baixo (poucos registros esperados)
- **A√ß√£o:** ‚úÖ **MANTER - Sem necessidade de limpeza**

**Query de verifica√ß√£o:**
```sql
SELECT
    status,
    COUNT(*) as quantidade,
    pg_size_pretty(pg_total_relation_size('manual_changes')) as tamanho
FROM manual_changes
GROUP BY status;
```

---

#### 1.3 `users` e `user_permissions`
- **Uso:** Autentica√ß√£o e controle de acesso
- **Impacto:** M√≠nimo (poucos usu√°rios)
- **A√ß√£o:** ‚úÖ **MANTER - Essencial**

---

### 2. **TABELA N√ÉO USADA PELO FRONTEND** ‚ùå

#### 2.1 `dre_fabric` - **PRINCIPAL CANDIDATA √Ä LIMPEZA**

**Status:** ‚ö†Ô∏è **N√ÉO √© usada pelo frontend**

**Fun√ß√£o:**
- Espelho dos dados do Microsoft Fabric Data Warehouse
- Usada APENAS para sincroniza√ß√£o batch via Python
- Dados j√° foram processados e movidos para `transactions`

**An√°lise de uso:**
```
‚úÖ Referenciada em: Scripts Python de sincroniza√ß√£o
‚úÖ Referenciada em: Arquivos SQL de batch processing
‚ùå N√ÉO referenciada em: Nenhum arquivo TypeScript/React
‚ùå N√ÉO referenciada em: services/supabaseService.ts
‚ùå N√ÉO referenciada em: Componentes do frontend
```

**Estrutura da tabela:**
```sql
CREATE TABLE dre_fabric (
    id BIGSERIAL PRIMARY KEY,
    chave TEXT,
    codlote TEXT,
    cia TEXT,
    filial TEXT,
    anomes TEXT,
    valor NUMERIC,
    complemento TEXT,
    recorrente TEXT,
    conta TEXT,
    tag1, tag2, tag3, tag4 TEXT,
    -- ... 39 colunas no total
);
```

**Queries de diagn√≥stico:**
```sql
-- 1. Verificar tamanho da tabela
SELECT
    pg_size_pretty(pg_total_relation_size('dre_fabric')) as tamanho_total,
    pg_size_pretty(pg_relation_size('dre_fabric')) as tamanho_dados,
    pg_size_pretty(pg_total_relation_size('dre_fabric') - pg_relation_size('dre_fabric')) as tamanho_indices
FROM pg_class
WHERE relname = 'dre_fabric';

-- 2. Contar registros
SELECT COUNT(*) as total_registros FROM dre_fabric;

-- 3. Verificar per√≠odo dos dados
SELECT
    MIN(anomes) as mes_mais_antigo,
    MAX(anomes) as mes_mais_recente,
    COUNT(DISTINCT anomes) as quantidade_meses
FROM dre_fabric;

-- 4. Analisar distribui√ß√£o por m√™s
SELECT
    anomes,
    COUNT(*) as quantidade,
    pg_size_pretty(SUM(pg_column_size(dre_fabric.*))) as tamanho_estimado
FROM dre_fabric
GROUP BY anomes
ORDER BY anomes DESC;
```

**RECOMENDA√á√ïES CR√çTICAS:**

**Op√ß√£o 1: REMOVER COMPLETAMENTE** (Recomendado se j√° sincronizou tudo)
```sql
-- ‚ö†Ô∏è CUIDADO: Fazer backup antes!
-- Se todos os dados j√° foram processados para 'transactions':
DROP TABLE IF EXISTS dre_fabric CASCADE;

-- Economia estimada: 50-80% do banco de dados
```

**Op√ß√£o 2: MANTER APENAS √öLTIMOS 3 MESES**
```sql
-- Deletar dados antigos (manter apenas √∫ltimos 3 meses)
DELETE FROM dre_fabric
WHERE anomes < TO_CHAR(CURRENT_DATE - INTERVAL '3 months', 'YYYYMM');

-- Depois, fazer VACUUM para recuperar espa√ßo
VACUUM FULL dre_fabric;
```

**Op√ß√£o 3: CRIAR TABELA PARTICIONADA**
```sql
-- Se precisar manter hist√≥rico, particionar por m√™s
-- (Requer migra√ß√£o - mais complexo)
```

---

### 3. **TABELAS DE SINCRONIZA√á√ÉO E HIST√ìRICO** ‚ö†Ô∏è

Estas tabelas foram mencionadas em arquivos SQL mas n√£o est√£o no schema principal:

#### 3.1 `cruzamento_dados_banco_vs_DRE`
- **Fun√ß√£o:** Hist√≥rico de compara√ß√µes entre `dre_fabric` e `transactions`
- **A√ß√£o:** ‚ùå **DELETAR - Dados tempor√°rios de debug**

```sql
-- Verificar se existe
SELECT COUNT(*) FROM cruzamento_dados_banco_vs_DRE;

-- Se n√£o for necess√°rio, deletar
DROP TABLE IF EXISTS cruzamento_dados_banco_vs_DRE CASCADE;
```

#### 3.2 `cruzamento_resumo`
- **Fun√ß√£o:** Resumo das compara√ß√µes
- **A√ß√£o:** ‚ùå **DELETAR - Dados tempor√°rios**

```sql
DROP TABLE IF EXISTS cruzamento_resumo CASCADE;
```

#### 3.3 `cruzamento_controle`
- **Fun√ß√£o:** Flag de sincroniza√ß√£o em andamento
- **A√ß√£o:** ‚úÖ **MANTER - Se ainda usa sincroniza√ß√£o**

#### 3.4 `conta_contabil`
- **Fun√ß√£o:** Lookup table para dados cont√°beis
- **A√ß√£o:** ‚úÖ **MANTER - Usada via API**

---

## üîç AN√ÅLISE DE √çNDICES

### √çndices na tabela `transactions`:

```sql
-- Verificar uso dos √≠ndices
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan as "Vezes Usado",
    idx_tup_read as "Tuplas Lidas",
    idx_tup_fetch as "Tuplas Retornadas",
    pg_size_pretty(pg_relation_size(indexrelid)) as "Tamanho"
FROM pg_stat_user_indexes
WHERE tablename = 'transactions'
ORDER BY idx_scan ASC;
```

**√çndices criados:**
1. `idx_transactions_date` - ‚úÖ Usado frequentemente
2. `idx_transactions_filial` - ‚úÖ Usado em filtros
3. `idx_transactions_marca` - ‚úÖ Usado em filtros
4. `idx_transactions_scenario` - ‚úÖ Usado nas abas
5. `idx_transactions_status` - ‚ö†Ô∏è Verificar uso
6. `idx_transactions_vendor` - ‚ö†Ô∏è Verificar uso
7. `idx_transactions_ticket` - ‚ö†Ô∏è Verificar uso
8. `idx_transactions_nat_orc` - ‚ö†Ô∏è Verificar uso
9. `idx_transactions_chave_id` - ‚úÖ Usado em joins

**A√ß√£o:**
```sql
-- Remover √≠ndices n√£o utilizados (se idx_scan = 0)
-- Exemplo:
-- DROP INDEX IF EXISTS idx_transactions_vendor;
```

---

## üìÅ ARQUIVOS DO PROJETO QUE OCUPAM ESPA√áO

### Arquivos para DELETAR IMEDIATAMENTE:

1. **`registros_com_erro_20260204_083748.json`** - 122 MB
   - Log de sincroniza√ß√£o com erro
   - ‚ùå N√£o √© necess√°rio manter

2. **`registros_com_erro_20260204_083748.xlsx`** - 17 MB
   - Exporta√ß√£o do JSON anterior
   - ‚ùå N√£o √© necess√°rio manter

3. **`validacao_100_linhas_20260203_112359.xlsx`** - 33 KB
   - Arquivo de teste
   - ‚ùå N√£o √© necess√°rio manter

4. **`validacao_100_linhas_20260203_113017.xlsx`** - 33 KB
   - Arquivo de teste
   - ‚ùå N√£o √© necess√°rio manter

5. **`relatorio_erro_sincronizacao_20260204_083748.txt`** - 28 KB
   - Log de erro
   - ‚ùå N√£o √© necess√°rio manter

**Comando para deletar:**
```bash
cd "C:\Users\edmilson.serafim\OneDrive - Raiz Educa√ß√£o S A\√Årea de Trabalho\Ap proposta"

del registros_com_erro_20260204_083748.json
del registros_com_erro_20260204_083748.xlsx
del validacao_100_linhas_20260203_112359.xlsx
del validacao_100_linhas_20260203_113017.xlsx
del relatorio_erro_sincronizacao_20260204_083748.txt
del erros_sincronizacao_*.json
```

**Economia:** ~156 MB no projeto (n√£o no banco)

---

### Arquivos para AVALIAR:

1. **`proposta de carga de dados.xlsx`** - 11 MB
   - ‚ö†Ô∏è Verificar se ainda √© necess√°rio
   - Se for apenas hist√≥rico ou staging, pode deletar

2. **`modelo ppt.pdf`** - 4.9 MB
   - ‚ö†Ô∏è Template de apresenta√ß√£o
   - Se estiver em outro local ou versionado, pode deletar

---

## üé¨ PLANO DE A√á√ÉO RECOMENDADO

### **FASE 1: DIAGN√ìSTICO (10 minutos)**

Execute estas queries no SQL Editor do Supabase para entender o tamanho atual:

```sql
-- 1. Tamanho total do banco
SELECT
    pg_size_pretty(pg_database_size(current_database())) as tamanho_banco;

-- 2. Tamanho de cada tabela
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS tamanho_total,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS tamanho_dados,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) AS tamanho_indices
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- 3. Contar registros em cada tabela
SELECT
    'transactions' as tabela, COUNT(*) as registros FROM transactions
UNION ALL
SELECT 'dre_fabric', COUNT(*) FROM dre_fabric
UNION ALL
SELECT 'manual_changes', COUNT(*) FROM manual_changes
UNION ALL
SELECT 'users', COUNT(*) FROM users;
```

---

### **FASE 2: LIMPEZA DE ARQUIVOS (5 minutos)**

```bash
# Deletar arquivos grandes do projeto
cd "C:\Users\edmilson.serafim\OneDrive - Raiz Educa√ß√£o S A\√Årea de Trabalho\Ap proposta"

# Deletar logs de erro (156 MB)
del registros_com_erro_20260204_083748.json
del registros_com_erro_20260204_083748.xlsx
del validacao_*.xlsx
del erros_sincronizacao_*.json
del relatorio_erro_*.txt

# Verificar economia
dir *.json *.xlsx
```

---

### **FASE 3: BACKUP (OBRIGAT√ìRIO - 30 minutos)**

‚ö†Ô∏è **ANTES DE DELETAR QUALQUER DADO DO BANCO, FA√áA BACKUP!**

**Op√ß√£o A: Backup via Supabase Dashboard**
1. V√° em: Database ‚Üí Backups
2. Crie um backup manual
3. Aguarde conclus√£o

**Op√ß√£o B: Backup via pg_dump (mais r√°pido)**
```bash
# Instalar PostgreSQL client tools
# Depois executar:

pg_dump "postgresql://[USER]:[PASSWORD]@[HOST]:5432/[DATABASE]" \
  --table=dre_fabric \
  --file=backup_dre_fabric_20260204.sql

pg_dump "postgresql://[USER]:[PASSWORD]@[HOST]:5432/[DATABASE]" \
  --table=transactions \
  --file=backup_transactions_20260204.sql
```

**Op√ß√£o C: Export para CSV (recomendado para `dre_fabric`)**
```sql
-- No SQL Editor do Supabase:
COPY dre_fabric TO '/tmp/dre_fabric_backup.csv' WITH CSV HEADER;
-- Depois baixe o arquivo via dashboard
```

---

### **FASE 4: DECIS√ÉO SOBRE `dre_fabric` (CR√çTICO)**

**Perguntas para responder:**

1. **Os dados de `dre_fabric` j√° foram todos processados e est√£o em `transactions`?**
   - ‚úÖ SIM ‚Üí Pode deletar `dre_fabric` completamente
   - ‚ùå N√ÉO ‚Üí Manter apenas √∫ltimos 3 meses

2. **Voc√™ ainda precisa sincronizar dados novos do Fabric?**
   - ‚úÖ SIM ‚Üí Manter tabela vazia ou com √∫ltimos 3 meses
   - ‚ùå N√ÉO ‚Üí Pode deletar completamente

3. **H√° algum processo batch/scheduled que usa `dre_fabric`?**
   - ‚úÖ SIM ‚Üí Verificar frequ√™ncia e ajustar reten√ß√£o
   - ‚ùå N√ÉO ‚Üí Pode deletar

---

### **FASE 5: LIMPEZA DO BANCO (30-60 minutos)**

#### **Cen√°rio A: Se pode deletar `dre_fabric` completamente**

```sql
-- 1. Verificar tamanho antes
SELECT pg_size_pretty(pg_total_relation_size('dre_fabric')) as tamanho_antes;

-- 2. Deletar a tabela
DROP TABLE IF EXISTS dre_fabric CASCADE;

-- 3. Deletar tabelas relacionadas (se existirem)
DROP TABLE IF EXISTS cruzamento_dados_banco_vs_DRE CASCADE;
DROP TABLE IF EXISTS cruzamento_resumo CASCADE;
DROP TABLE IF EXISTS dre_fabric_agrupado CASCADE;

-- 4. Fazer VACUUM para recuperar espa√ßo
VACUUM FULL;

-- 5. Verificar economia
SELECT pg_size_pretty(pg_database_size(current_database())) as tamanho_depois;
```

**Economia estimada:** 50-80% do banco

---

#### **Cen√°rio B: Se precisa manter `dre_fabric` para sincroniza√ß√£o futura**

```sql
-- 1. Verificar distribui√ß√£o de dados
SELECT
    anomes,
    COUNT(*) as registros,
    pg_size_pretty(SUM(pg_column_size(dre_fabric.*))) as tamanho
FROM dre_fabric
GROUP BY anomes
ORDER BY anomes DESC;

-- 2. Deletar dados antigos (manter apenas √∫ltimos 3 meses)
DELETE FROM dre_fabric
WHERE anomes < TO_CHAR(CURRENT_DATE - INTERVAL '3 months', 'YYYYMM');

-- 3. Fazer VACUUM FULL para recuperar espa√ßo
VACUUM FULL dre_fabric;

-- 4. Recriar √≠ndices otimizados
REINDEX TABLE dre_fabric;
```

**Economia estimada:** 40-60% do banco

---

#### **Cen√°rio C: Limpar registros antigos de `transactions`**

```sql
-- 1. Verificar distribui√ß√£o de dados
SELECT
    DATE_TRUNC('year', date::date) as ano,
    COUNT(*) as registros,
    pg_size_pretty(SUM(pg_column_size(transactions.*))) as tamanho
FROM transactions
GROUP BY ano
ORDER BY ano DESC;

-- 2. Criar tabela de arquivo hist√≥rico (opcional)
CREATE TABLE transactions_archive AS
SELECT * FROM transactions
WHERE date < (CURRENT_DATE - INTERVAL '24 months');

-- 3. Deletar registros antigos (mais de 2 anos)
DELETE FROM transactions
WHERE date < (CURRENT_DATE - INTERVAL '24 months');

-- 4. Fazer VACUUM
VACUUM FULL transactions;
```

**Economia estimada:** 20-40% do tamanho de `transactions`

---

### **FASE 6: OTIMIZA√á√ÉO P√ìS-LIMPEZA (15 minutos)**

```sql
-- 1. Analisar estat√≠sticas das tabelas
ANALYZE;

-- 2. Recriar √≠ndices
REINDEX DATABASE postgres;

-- 3. Verificar √≠ndices n√£o utilizados
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    pg_size_pretty(pg_relation_size(indexrelid)) as tamanho
FROM pg_stat_user_indexes
WHERE idx_scan = 0
  AND schemaname = 'public'
ORDER BY pg_relation_size(indexrelid) DESC;

-- 4. Deletar √≠ndices n√£o utilizados (se houver)
-- DROP INDEX IF EXISTS nome_do_indice;
```

---

## üìä RESULTADOS ESPERADOS

### **Antes da Otimiza√ß√£o:**
- Banco Supabase: ~450-490 MB (perto do limite de 500 MB)
- Projeto local: ~340 MB (com logs e arquivos tempor√°rios)

### **Depois da Otimiza√ß√£o (Cen√°rio Completo):**
- Banco Supabase: ~100-150 MB (economia de 70-75%)
- Projeto local: ~180 MB (economia de ~160 MB)

### **Depois da Otimiza√ß√£o (Cen√°rio Conservador):**
- Banco Supabase: ~200-250 MB (economia de 50%)
- Projeto local: ~180 MB (economia de ~160 MB)

---

## ‚ö†Ô∏è AVISOS IMPORTANTES

### **ANTES DE EXECUTAR QUALQUER COMANDO:**

1. ‚úÖ **Fazer backup completo do banco**
2. ‚úÖ **Testar queries de diagn√≥stico primeiro**
3. ‚úÖ **Validar que dados est√£o em `transactions`**
4. ‚úÖ **Informar a equipe sobre a manuten√ß√£o**
5. ‚úÖ **Executar em hor√°rio de baixa utiliza√ß√£o**

### **AP√ìS A LIMPEZA:**

1. ‚úÖ **Testar aplica√ß√£o completamente**
2. ‚úÖ **Verificar se sincroniza√ß√µes ainda funcionam**
3. ‚úÖ **Monitorar tamanho do banco**
4. ‚úÖ **Documentar mudan√ßas realizadas**

---

## üîÑ MANUTEN√á√ÉO CONT√çNUA

### **Recomenda√ß√µes para evitar crescimento excessivo:**

1. **Pol√≠tica de reten√ß√£o de dados:**
   ```sql
   -- Criar job agendado para deletar dados antigos
   -- (Supabase n√£o suporta pg_cron no plano free, usar API/script externo)
   ```

2. **Monitoramento de tamanho:**
   ```sql
   -- Criar view para monitorar tamanho
   CREATE OR REPLACE VIEW v_tamanho_tabelas AS
   SELECT
       tablename,
       pg_size_pretty(pg_total_relation_size('public.'||tablename)) AS tamanho
   FROM pg_tables
   WHERE schemaname = 'public'
   ORDER BY pg_total_relation_size('public.'||tablename) DESC;
   ```

3. **Limpeza peri√≥dica:**
   - Executar `VACUUM FULL` mensalmente
   - Revisar e deletar tabelas tempor√°rias
   - Arquivar dados antigos

4. **Otimiza√ß√£o de queries:**
   - Usar `LIMIT` em queries grandes
   - Implementar pagina√ß√£o adequada
   - Carregar apenas √∫ltimos 3-6 meses por padr√£o

---

## üìû PR√ìXIMOS PASSOS

1. **Execute o diagn√≥stico (Fase 1)**
2. **Analise os resultados e decida sobre `dre_fabric`**
3. **Fa√ßa o backup (obrigat√≥rio)**
4. **Execute a limpeza em etapas**
5. **Monitore os resultados**

---

**Relat√≥rio gerado em:** 04/02/2026
**Analista:** Claude Code AI
**Vers√£o:** 1.0
